                                                        // Lab Execution Steps //

# Copy files to MySQL container and Spark Container.

Â docker cp /home/labuser/Project/Installation_and_Execution/postgresql-42.3.1.jar hdp_spark-master:/spark/jars/
Â docker cp hdp_hive-server:/opt/hive/conf/hive-site.xml /home/labuser/Downloads/
Â docker cp /home/labuser/Downloads/hive-site.xml hdp_spark-master:/spark/conf/
Â docker cp /home/labuser/Project/Code/ ra_mysql:/opt/Code
 docker cp /home/labuser/Project/Code hdp_hive-server:/opt/

1. Refer 01_partial_dataset_creation.sql contains MYsql table creation commands for partial dataset and view for importing data.
Â 
Â docker exec -i -t ra_mysql bash
Â mysql -u root -p
Â password- example
Â source /opt/Code/01_partial_dataset_creation.sql;

2. Refer 03_Sqoop-import-commands.txt , contains scoop import commands to import data from Mysql database.

Â docker exec -i -t ra_sqoop bash

Â sqoop import --connect jdbc:mysql://ra_mysql:3306/testdb --username root --target-dir /input/customerdemo/ --query 'SELECT CustomerID, AccountNumber, CustomerType, Demographics, TerritoryID, ModifiedDate FROM v_customer_demo WHERE $CONDITIONS' --split-by CustomerID --password example

Â sqoop import --connect jdbc:mysql://ra_mysql:3306/testdb --username root --password example --query 'SELECT CreditCardID, CardType, CardNumber, ExpMonth, ExpYear, ModifiedDate FROM ccard WHERE $CONDITIONS' --split-by CreditCardID --target-dir /input/creditcard/

4. Refer 04_Hive_tables_creation.hql , Contains HIVE tables create statements.

Â docker exec -i -t hdp_hive-server bash
Â hive
Â source /opt/Code/04_Hive_tables_creation.hql;

5. Refer 05_customer_demographic.scala , this is used to fetch demographic XML values into Parquet files.

Â docker cp /home/labuser/Project/Code/05_customer_demographic.scala hdp_spark-master:/spark/
Â docker exec -i -t hdp_spark-master bash
Â ./spark/bin/spark-shell
Â :load /spark/05_customer_demographic.scala

6. Copy the parquet files from spark container to hive container.

Â docker cp hdp_spark-master:/customer_demographics_xml_mined /home/labuser/
Â docker cp /home/labuser/customer_demographics_xml_mined hdp_hive-server:/opt/

7. Refer 07_customer_demograhics_creation.hql , Creating demographic parquet tables and loading data for performing HIVE analytics.
Â 
Â docker exec -i -t hdp_hive-server bash
Â hive
Â 
8. Refer 08_Hive_analytic_queries.hql , contains advanced analytic queries used on demographics tables.

Note :
        Data Flow ==> Mysql -> Sqoop -> HDFS -> HIVE -> SPARK -> HIVE
